{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junting-huang/data_storytelling/blob/main/case_3_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADFl_LlomYTN"
      },
      "source": [
        "# case_5.statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP3h2ItGqVJn"
      },
      "source": [
        "## 5.1 language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaRUkgc0wDL7"
      },
      "source": [
        "**Markov Chain Language Model**\n",
        "\n",
        "\"A language model is a probabilistic model of a natural language that can generate probabilities of a series of words, based on text corpora in one or multiple languages it was trained on.\" In a simple Markov chain language model, the probability of each word only depends on the last word in the sequence. For example, given the word \"the,\" the model might predict that the next word is \"cat\" with a probability of 0.2, \"dog\" with a probability of 0.3, and so on, based on the frequencies of word sequences in the training data.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Consider a corpus with the sentence: \"I like to eat apples. I like to eat bananas.\" A simple bigram (2nd order) Markov chain model might create a probability distribution like this:\n",
        "\n",
        "- P(like | I) = 1.0 (since \"like\" always follows \"I\" in the training data)\n",
        "- P(to | like) = 1.0 (since \"to\" always follows \"like\" in the training data)\n",
        "- P(eat | to) = 1.0 (since \"eat\" always follows \"to\" in the training data)\n",
        "- P(apples | eat) = 0.5, P(bananas | eat) = 0.5 (since \"apples\" and \"bananas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4yR_TD2vrUF"
      },
      "source": [
        "## 5.2 building model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, import the Walden text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VLCQU7eNusvm"
      },
      "outputs": [],
      "source": [
        "filename = 'data/walden.txt'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    text = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The *re* module in Python stands for regular expressions. It provides support for regular expressions, which are powerful tools for pattern matching and string manipulation. Regular expressions allow you to search, match, and manipulate text based on patterns.\n",
        "\n",
        "re.findall is a function from the *re* module that searches for all occurrences of a pattern in a string.\n",
        "\n",
        "* \\b: Word boundary. This ensures that we match whole words and not parts of words.\n",
        "* \\w+: One or more word characters. This matches letters, digits, or underscores.\n",
        "* \\b: Another word boundary to complete the pattern.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PLeHRG65uzEk"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "words = re.findall(r'\\b\\w+\\b', text.lower())  # Convert to lowercase and split into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "120548"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are ready to build our first language model!\n",
        "\n",
        "The *defaultdict* class from the *collections* module is a specialized dictionary that allows you to specify a default value for any new key that is accessed for the first time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SkB2biSXu497"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_model(words, order=1):\n",
        "    model = defaultdict(list)\n",
        "    for i in range(len(words) - order):\n",
        "        state = tuple(words[i:i + order])\n",
        "        next_word = words[i + order]\n",
        "        model[state].append(next_word)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLqsViiGxL63"
      },
      "source": [
        "## 5.3 text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yJ-fATV9u7hg"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_poetry(model, order, length=50):\n",
        "    state = random.choice(list(model.keys()))\n",
        "    poetry = list(state)\n",
        "    for _ in range(length):\n",
        "        if state in model:  # Check if the state is in the model\n",
        "            next_word = random.choice(model[state])\n",
        "            poetry.append(next_word)\n",
        "            state = tuple(poetry[-order:])  # Update the state with the last 'order' words\n",
        "        else:  # If the state is not in the model, stop generating\n",
        "            break\n",
        "\n",
        "    # Split the generated poetry into four lines\n",
        "    words_per_line = len(poetry) // 4\n",
        "    lines = [ ' '.join(poetry[i:i + words_per_line]) for i in range(0, len(poetry), words_per_line) ]\n",
        "\n",
        "    # Join the lines with line breaks to form the final poem\n",
        "    return '\\n'.join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI59Bdn3vP8u"
      },
      "source": [
        "## 5.4 n-gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYTRTWMuu9jc",
        "outputId": "ae1f63d9-7e92-4972-9c59-06c896f1103e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "infinity of the savages their bodies is in this case now for\n",
            "by hounds that will be your head useful systems for their semi\n",
            "cylindrical form the expression he goes so sincerely proposed a cloud compeller\n",
            "would be basis let time we are inclined to hummock left by\n",
            "this continent that\n"
          ]
        }
      ],
      "source": [
        "order = 1  # You can experiment with different orders\n",
        "model = build_model(words, order)\n",
        "poetry = generate_poetry(model, order, length=50)\n",
        "print(poetry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sat thus with the full project gutenberg works unless you plant more than\n",
            "those other productions but which at noon sitting amid the rustling of leaves\n",
            "and potamogetons and perhaps cannot be removed without girdling and so there were\n",
            "but poorly entertained though what they have persuaded the majority are able at\n"
          ]
        }
      ],
      "source": [
        "order = 2  # You can experiment with different orders\n",
        "model = build_model(words, order)\n",
        "poetry = generate_poetry(model, order, length=50)\n",
        "print(poetry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtdxymNCsSS1"
      },
      "source": [
        "## 5.5 markovify library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Package *markovify* is a simple, extensible Markov chain generator. Uses include generating random semi-plausible sentences based on an existing text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHSRJWQFradB",
        "outputId": "4854c93e-ff9b-416f-93d3-e680ccfe6b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: markovify in /Users/liyao/anaconda3/envs/py38/lib/python3.8/site-packages (0.9.4)\n",
            "Requirement already satisfied: unidecode in /Users/liyao/anaconda3/envs/py38/lib/python3.8/site-packages (from markovify) (1.3.8)\n"
          ]
        }
      ],
      "source": [
        "! pip install markovify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a Markov chain text model using the NewlineText class from markovify. This class is suitable when the source text has newline-separated sentences or paragraphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jwamDCYNrcW5"
      },
      "outputs": [],
      "source": [
        "import markovify\n",
        "\n",
        "filename = 'data/walden.txt'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "text_model = markovify.NewlineText(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After creating the text_model, you can use it to generate new sentences or poems based on the patterns learned from the input text Walden. Here's a simple example of generating a poem using the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_6kraT_roxA",
        "outputId": "1aec579c-3e93-4066-dab3-16141c7bbf45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I had a farm, or ten dollars, or all which had stood in a high state of the great ocean of solitude, into which the owner said protected it by a thousand as well omit to study the bottom.\n"
          ]
        }
      ],
      "source": [
        "def generate_poem(model, length=10):\n",
        "    return model.make_sentence(max_words=40,tries=100)\n",
        "\n",
        "print(generate_poem(text_model))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPkUKAsn8Dz0ovIF1EyaqQY",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
