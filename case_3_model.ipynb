{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkUKAsn8Dz0ovIF1EyaqQY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junting-huang/data_storytelling/blob/main/case_3_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# case_3. model"
      ],
      "metadata": {
        "id": "ADFl_LlomYTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 language model"
      ],
      "metadata": {
        "id": "BP3h2ItGqVJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Markov Chain Language Model**\n",
        "\n",
        "\"A language model is a probabilistic model of a natural language that can generate probabilities of a series of words, based on text corpora in one or multiple languages it was trained on.\" In a simple Markov chain language model, the probability of each word only depends on the last word in the sequence. For example, given the word \"the,\" the model might predict that the next word is \"cat\" with a probability of 0.2, \"dog\" with a probability of 0.3, and so on, based on the frequencies of word sequences in the training data.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Consider a corpus with the sentence: \"I like to eat apples. I like to eat bananas.\" A simple bigram (2nd order) Markov chain model might create a probability distribution like this:\n",
        "\n",
        "- P(like | I) = 1.0 (since \"like\" always follows \"I\" in the training data)\n",
        "- P(to | like) = 1.0 (since \"to\" always follows \"like\" in the training data)\n",
        "- P(eat | to) = 1.0 (since \"eat\" always follows \"to\" in the training data)\n",
        "- P(apples | eat) = 0.5, P(bananas | eat) = 0.5 (since \"apples\" and \"bananas"
      ],
      "metadata": {
        "id": "HaRUkgc0wDL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 building model"
      ],
      "metadata": {
        "id": "w4yR_TD2vrUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'walden.txt'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    text = file.read()"
      ],
      "metadata": {
        "id": "VLCQU7eNusvm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "words = re.findall(r'\\b\\w+\\b', text.lower())  # Convert to lowercase and split into words"
      ],
      "metadata": {
        "id": "PLeHRG65uzEk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_model(words, order=1):\n",
        "    model = defaultdict(list)\n",
        "    for i in range(len(words) - order):\n",
        "        state = tuple(words[i:i + order])\n",
        "        next_word = words[i + order]\n",
        "        model[state].append(next_word)\n",
        "    return model"
      ],
      "metadata": {
        "id": "SkB2biSXu497"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 text generation"
      ],
      "metadata": {
        "id": "pLqsViiGxL63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_poetry(model, order, length=50):\n",
        "    state = random.choice(list(model.keys()))\n",
        "    poetry = list(state)\n",
        "    for _ in range(length):\n",
        "        if state in model:  # Check if the state is in the model\n",
        "            next_word = random.choice(model[state])\n",
        "            poetry.append(next_word)\n",
        "            state = tuple(poetry[-order:])  # Update the state with the last 'order' words\n",
        "        else:  # If the state is not in the model, stop generating\n",
        "            break\n",
        "\n",
        "    # Split the generated poetry into four lines\n",
        "    words_per_line = len(poetry) // 4\n",
        "    lines = [ ' '.join(poetry[i:i + words_per_line]) for i in range(0, len(poetry), words_per_line) ]\n",
        "\n",
        "    # Join the lines with line breaks to form the final poem\n",
        "    return '\\n'.join(lines)"
      ],
      "metadata": {
        "id": "yJ-fATV9u7hg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 n-gram"
      ],
      "metadata": {
        "id": "qI59Bdn3vP8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = 1  # You can experiment with different orders\n",
        "model = build_model(words, order)\n",
        "poetry = generate_poetry(model, length=50)\n",
        "print(poetry)"
      ],
      "metadata": {
        "id": "tYTRTWMuu9jc",
        "outputId": "ae1f63d9-7e92-4972-9c59-06c896f1103e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worldly goods store he can learn what depth of least in a spreading white quartz perhaps it may see my light some faith and civil government are acquainted with any hammering stone was sheer idleness it swept and i used to the last seed 0 65 apples only slaves of the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 markovify library"
      ],
      "metadata": {
        "id": "JtdxymNCsSS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install markovify"
      ],
      "metadata": {
        "id": "FHSRJWQFradB",
        "outputId": "4854c93e-ff9b-416f-93d3-e680ccfe6b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode (from markovify)\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18607 sha256=f028753a36ef9dd2ac0707c0967743de607d4b49cd401f6726030f0a530ebbcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/8c/c5/41413e24c484f883a100c63ca7b3b0362b7c6f6eb6d7c9cc7f\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.4 unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import markovify\n",
        "\n",
        "filename = 'walden.txt'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "text_model = markovify.NewlineText(text)"
      ],
      "metadata": {
        "id": "jwamDCYNrcW5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poem(model, length=10):\n",
        "    return model.make_sentence(max_words=40,tries=100)\n",
        "\n",
        "print(generate_poem(text_model))"
      ],
      "metadata": {
        "id": "U_6kraT_roxA",
        "outputId": "1aec579c-3e93-4066-dab3-16141c7bbf45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "While I enjoy the most part it suggested only pleasing associations, whether heard by the carriage road from Brister’s Hill.\n"
          ]
        }
      ]
    }
  ]
}