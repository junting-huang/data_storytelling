{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junting-huang/data_storytelling/blob/main/case_1_narrative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUrLBPV3Qdpt"
      },
      "source": [
        "# case_1. narrative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The technique of understanding and extracting valuable information from human language is called Natural Language Processing (NLP). This is one of the most important topics in machine learning and is used in various aspects of our life. Python language helps us with NLP with its plethora of libraries. \n",
        "\n",
        "One such library is TextBlob. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. More information can be found: https://textblob.readthedocs.io/en/dev/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPkq74HLWLvm"
      },
      "source": [
        "## 1.1 installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The process is quick and simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tqDxERkWnEC",
        "outputId": "61aa3161-19b7-4c7a-d401-33d54ad2f674"
      },
      "outputs": [],
      "source": [
        "! pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd1UgyKtbbhc",
        "outputId": "76afdddf-7885-4495-f572-fe46e449e1f5"
      },
      "outputs": [],
      "source": [
        "! python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwUyLnQYV3qI"
      },
      "source": [
        "## 1.2 basic usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TextBlob aims to provide access to common text-processing operations through a familiar interface. You can treat TextBlob objects as if they were Python strings that learned how to do Natural Language Processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, the import."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhMDu1yhXNzc"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s create our first TextBlob. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK1Mt16rX4Hg"
      },
      "outputs": [],
      "source": [
        "blob = TextBlob(\"When I wrote the following pages, or rather the bulk of them, I lived alone, in the woods, a mile from any neighbor, in a house which I had built myself, on the shore of Walden Pond, in Concord, Massachusetts, and earned my living by the labor of my hands only. \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part-of-speech Tagging\n",
        "\n",
        "Part-of-speech tagging, better known as POS tagging, is a natural language processing task that involves assigning a grammatical category (such as noun, verb, adjective, etc.) to each word in a text. This process is essential for several reasons:\n",
        "\n",
        "* Syntax Analysis: Part-of-speech tagging helps in understanding the syntactic structure of a sentence. Identifying the part of speech of each word allows for the analysis of how words relate to each other in a grammatical sense.\n",
        "\n",
        "* Semantic Analysis: It aids in understanding the meaning of words in context. Different parts of speech convey different semantic roles, and knowing the part of speech can provide insights into the intended meaning of a word.\n",
        "\n",
        "* Information Retrieval: Part-of-speech tagging is crucial in information retrieval systems. It enables more accurate and relevant searches by considering the grammatical roles of words in queries and documents.\n",
        "\n",
        "\n",
        "Part-of-speech tags can be accessed through the tags property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtCAIT5GX-5U",
        "outputId": "ec76fb9f-4fc0-4aaf-a5ee-827b54faafa9"
      },
      "outputs": [],
      "source": [
        "print(blob.tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Noun Phrase Extraction\n",
        "\n",
        "Noun phrase extraction is a natural language processing (NLP) task that involves identifying and extracting noun phrases from a given text. A noun phrase is a group of words that function as a unit and includes a noun (the head) along with its modifiers. The process of noun phrase extraction serves several important purposes:\n",
        "\n",
        "* Semantic Analysis: Noun phrases often represent meaningful units of information in a sentence. Extracting them helps in understanding the key entities and concepts discussed in the text, contributing to semantic analysis.\n",
        "\n",
        "* Information Retrieval: Noun phrases play a crucial role in information retrieval systems. By extracting relevant noun phrases from documents, search engines can improve the accuracy of search results and help users find information more effectively.\n",
        "\n",
        "* Named Entity Recognition (NER): Noun phrase extraction is closely related to named entity recognition. Many named entities, such as people, organizations, and locations, are often part of noun phrases. Extracting noun phrases can be a preliminary step in identifying and categorizing named entities.\n",
        "\n",
        "\n",
        "Similarly, noun phrases are accessed through the noun_phrases property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pCvZ6vzYCk1",
        "outputId": "4dcbc315-3e47-43d4-fd30-26348910ed02"
      },
      "outputs": [],
      "source": [
        "print(blob.noun_phrases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization\n",
        "\n",
        "Tokenization is the process of separating each word in the sentence into a list so that it can be easily interpreted and manipulated later. It takes one line of code to implement tokenization using TextBlob library.\n",
        "\n",
        "You can break TextBlobs into words or sentences. Sentence objects have the same properties and methods as TextBlobs. For more advanced tokenization, see the Advanced Usage guide: https://textblob.readthedocs.io/en/dev/advanced_usage.html#advanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blob.words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blob.sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Words Inflection and Lemmatization\n",
        "\n",
        "Each word in TextBlob.words or Sentence.words is a Word object (a subclass of unicode) with useful methods, e.g. for word inflection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(blob.words[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(blob.words[5].singularize())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(blob.words[19])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(blob.words[19].pluralize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lemmatization refers to reducing the word to its root form, as found in a dictionary. Lemmatization considers the context and converts the word to its meaningful base form. It is responsible for grouping different inflected forms of words into the root form, having the same meaning. For instance, stemming the word ‘Caring‘ would return ‘Car‘ whereas lemmatizing the word ‘Caring‘ would return ‘Care‘.\n",
        "\n",
        "To perform lemmatization via TextBlob, you have to use the Word object from the textblob library, pass it the word that you want to lemmatize, and then call the lemmatize method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(blob.words[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QWWCCw1YHLq",
        "outputId": "50464016-f3b7-433a-d8af-442735a11321"
      },
      "outputs": [],
      "source": [
        "print(blob.words[2].lemmatize('v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(blob.words[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_i9HM9vadpE",
        "outputId": "ec6939fe-d9c0-49e9-9da3-4d8213923c7d"
      },
      "outputs": [],
      "source": [
        "print(blob.words[4].stem())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A complete tutorial from TextBlob official website can be found here: https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart. Here is another great article about TextBlob for your reference: https://www.scaler.com/topics/nlp/nlp-textblob/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 labeling agent/action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "During the course, you will have the opportunity to explore several other Python packages designed for natural language processing. Some popular libraries include:\n",
        "\n",
        "* spaCy: This is a highly popular NLP library in Python, known for its efficiency and ease of use. It can be used to parse sentences and identify various grammatical components, including the subject (agent) of the sentence.\n",
        "\n",
        "* NLTK (Natural Language Toolkit): This is another widely-used library for NLP in Python. It provides tools for sentence parsing and can be used to identify the subject of a sentence, although it might require more manual effort compared to spaCy.\n",
        "\n",
        "In this section, we are going to demonstrate how to label agent/action in a given sentence using spaCy package. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"John eats an apple.\"\n",
        "\n",
        "# Process the sentence with spaCy\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# Find the subject (agent) of the sentence\n",
        "agent = None\n",
        "for token in doc:\n",
        "    if token.dep_ == \"nsubj\" and token.head.dep_ == \"ROOT\":\n",
        "        agent = token.text\n",
        "\n",
        "# Print the labeled agent\n",
        "print(\"Labeled Agent:\", agent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the root verb (action) of the sentence\n",
        "action = None\n",
        "for token in doc:\n",
        "    if token.dep_ == \"ROOT\":\n",
        "        action = token.text\n",
        "\n",
        "# Print the labeled action\n",
        "print(\"Labeled Action:\", action)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 labeling poetic style\n",
        "\n",
        "Labeling the poetic style of a text is a more subjective and complex task compared to tasks like part-of-speech tagging. Poetic style encompasses various elements such as metaphors, imagery, rhyme, rhythm, and more. Here's an example using spaCy to identify metaphors in a text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example poetic text\n",
        "poetic_text = \"The stars danced in the night sky, painting a canvas of dreams.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(poetic_text)\n",
        "\n",
        "# Identify metaphors (simplified example)\n",
        "metaphors = []\n",
        "for token in doc:\n",
        "    if token.dep_ == \"prep\" and token.head.pos_ == \"NOUN\":\n",
        "        metaphors.append((token.head.text, token.text))\n",
        "\n",
        "# Print identified metaphors\n",
        "print(\"Identified Metaphors:\", metaphors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, it looks for prepositions (prep) followed by nouns, assuming that metaphors often involve comparing one thing to another. This is a simplistic approach, and identifying poetic style comprehensively would likely involve more advanced techniques and possibly machine learning models trained on poetic corpora."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
