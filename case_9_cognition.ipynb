{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# case_9. cognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course materials for Computational Humanities: Critical Approaches to Literature as Data (David Bamman and Tom McEnaney, Fall 2020).\n",
    "\n",
    "This material is based upon work supported by the National Science Foundation for the projects \"CAREER: Using Fiction to Improve Real-World Information Systems\" (IIS-1942591) and \"SubjectiveKB: Building subjective knowledge bases by modeling viewpoints\" (IIS-1813470).\n",
    "\n",
    "Notebook is adapted from: https://github.com/dbamman/comphumF20/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the degree to which different characters have measurably different *registers* by training a multiclass classifier on character dialogue to predict the speaker.  This notebooks works with the output of [BookNLP](https://github.com/dbamman/book-nlp), which recognizes quotations and carries out speaker attribution on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from collections import Counter\n",
    "import math\n",
    "from os import path\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from scipy import sparse\n",
    "import nltk\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gzip\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Obtaining dependency information for textstat from https://files.pythonhosted.org/packages/d8/33/302083f47386d651e4b42923f5206eeb9ee0545ea94bb506324d05fd2274/textstat-0.7.3-py3-none-any.whl.metadata\n",
      "  Downloading textstat-0.7.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyphen (from textstat)\n",
      "  Obtaining dependency information for pyphen from https://files.pythonhosted.org/packages/e3/c3/556e4ed0402ad7810a828532d539f1b14884fc0ff6c2da8ab401bf3bbd63/pyphen-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading pyphen-0.14.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
      "Successfully installed pyphen-0.14.0 textstat-0.7.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install textstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The textstat package in Python is a library designed to provide simple calculations and statistics for text data. It offers various functions to analyze and extract information from text, such as readability scores, word and sentence counts, syllable counts, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: count the number of quotes in the book by different characters\n",
    "# and print the top-n characters which have the most quotes.\n",
    "def print_top_speakers(filename, top_n=10):\n",
    "        \n",
    "    with gzip.open(filename) as file:\n",
    "        data=json.load(file)\n",
    "        counts={}\n",
    "\n",
    "        for character in data[\"characters\"]:\n",
    "            char_id=character[\"id\"]\n",
    "\n",
    "            gender=character[\"g\"]\n",
    "            names='; '.join([x[\"n\"] for x in character[\"names\"]])\n",
    "            quotes=0\n",
    "            for q in character[\"speaking\"]:\n",
    "                quotes+=1\n",
    "            counts[(char_id, names)]=quotes\n",
    "\n",
    "        sorted_x = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        print(\"#quotes\\tchar_id\\tname\")\n",
    "        for (charid,name),v in sorted_x[:top_n]:\n",
    "            print(\"%s\\t%s\\t%s\" % (v,charid, name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first just examine the characters who have the most dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#quotes\tchar_id\tname\n",
      "8014\t343\tHarry; Potter; Harry Potter; James; James Potter; POTTER; HARRY; HARRY POTTER; Harry James Potter; JAMES\n",
      "3270\t247\tRon; Weasley; Ron Weasley; WEASLEY; RON\n",
      "2998\t302\tHermione; Miss Granger; Hermione Granger; Granger; Miss Hermione Granger\n",
      "1307\t352\tDumbledore; Albus; Albus Dumbledore; DUMBLEDORE; ALBUS DUMBLEDORE\n",
      "726\t298\tHagrid; Rubeus Hagrid; Rubeus\n",
      "723\t561\tFred; George; Fred -- George; GEORGE\n",
      "647\t389\tSnape; Severus; Severus Snape; SEVERUS SNAPE; SNAPE\n",
      "442\t563\tMrs. Weasley\n",
      "414\t200\tMr. Weasley; Ronald; Ronald Weasley; Mr. Ronald Weasley\n",
      "412\t489\tSirius; Black; Sirius Black; SIRIUS\n"
     ]
    }
   ],
   "source": [
    "print_top_speakers(\"data/harry_potter.book.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#quotes\tchar_id\tname\n",
      "1066\t216\tFrodo; Mr. Frodo; Mr. Baggins; Frodo Baggins; Baggins; Mr. Frodo Baggins; Mr. FRODO\n",
      "686\t106\tSam; Sam Gamgee; Gamgee\n",
      "675\t49\tGandalf; Gandalf Greyhame\n",
      "240\t317\tGimli; Gloin; Gimli Gloin; Gimli son of Gloin\n",
      "230\t259\tLegolas; Legolas Greenleaf\n",
      "183\t2\tMerry; Merry Brandybuck; Brandybuck\n",
      "174\t215\tFaramir; Lord Faramir; lord Faramir\n",
      "146\t54\tStrider; Mr. Strider\n",
      "121\t281\tTheoden; Theoden King; King\n",
      "117\t274\tPippin; Mr. Pippin\n"
     ]
    }
   ],
   "source": [
    "print_top_speakers(\"data/lotr.book.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function iterates over the characters in the data dictionary. For each character, it checks if the character ID (char_id) is present in the targets dictionary. If it is, the function extracts the proper name of the character from the targets dictionary. Then, for each quote spoken by the character, the function tokenizes the quote into words using nltk.word_tokenize and appends the resulting tokens to the quotes list. After all quotes for the character are collected, the function shuffles the quotes list randomly. It then asserts that the number of quotes is greater than or equal to max_num. Finally, the function extends the X list with the first max_num shuffled quotes and extends the Y list with the corresponding character's proper name repeated max_num times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: retrieve max_num quotes and construct a quote-character pair.\n",
    "def get_quote_data(data, targets, max_num):\n",
    "            \n",
    "    X=[]\n",
    "    Y=[]\n",
    "    \n",
    "    for character in data[\"characters\"]:\n",
    "        proper_name_count=character[\"NNPcount\"]\n",
    "        char_id=character[\"id\"]\n",
    "        if char_id in targets:\n",
    "            name=targets[char_id]\n",
    "            quotes=[]\n",
    "            for q in character[\"speaking\"]:\n",
    "                quote=q[\"w\"].lower()\n",
    "                tokens=nltk.word_tokenize(quote)\n",
    "                quotes.append(tokens)\n",
    "            \n",
    "            random.shuffle(quotes)\n",
    "            \n",
    "            assert len(quotes) >= max_num\n",
    "                \n",
    "            X.extend(quotes[:max_num])\n",
    "            Y.extend([name]*max_num)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: call get_quote_data \n",
    "def read_data(filename, targets, max_num):\n",
    "\n",
    "    with gzip.open(filename) as file:\n",
    "        data=json.load(file)\n",
    "        X, Y=get_quote_data(data, targets, max_num)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build features by given feature function which is defined in the following code. Feel free to ignore the helper functions. They are used to build up the machine learning pipeline which is out of scope for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(dataX, feature_functions):\n",
    "    \n",
    "    \"\"\" This function featurizes the data according to the list of parameter feature_functions \"\"\"\n",
    "    \n",
    "    data=[]\n",
    "    for tokens in dataX:\n",
    "        feats={}\n",
    "        \n",
    "        for function in feature_functions:\n",
    "            feats.update(function(tokens))\n",
    "\n",
    "        data.append(feats)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_to_ids(data, feature_vocab):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    This helper function converts a dictionary of feature names to a sparse representation\n",
    " that we can fit in a scikit-learn model.  This is important because almost all feature \n",
    " values will be 0 for most documents (note: why?), and we don't want to save them all in \n",
    " memory.\n",
    "\n",
    "    \"\"\"\n",
    "    new_data=sparse.lil_matrix((len(data), len(feature_vocab)))\n",
    "    for idx,doc in enumerate(data):\n",
    "        for f in doc:\n",
    "            if f in feature_vocab:\n",
    "                new_data[idx,feature_vocab[f]]=doc[f]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(data, top_n=None):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    This helper function converts a dictionary of feature names to unique numerical ids. \n",
    "    top_n limits the features to only the n most frequent features observed in the training data \n",
    "    (in terms of the number of documents that contains it).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    counts=Counter()\n",
    "    for doc in data:\n",
    "        for feat in doc:\n",
    "            counts[feat]+=1\n",
    "\n",
    "    feature_vocab={}\n",
    "\n",
    "    for idx, (k, v) in enumerate(counts.most_common(top_n)):\n",
    "        feature_vocab[k]=idx\n",
    "                \n",
    "    return feature_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(trainX, devX, trainY, devY, feature_functions):\n",
    "\n",
    "    \"\"\" This function evaluates a list of feature functions on the training/dev data arguments \"\"\"\n",
    "    \n",
    "    trainX_feat=build_features(trainX, feature_functions)\n",
    "    devX_feat=build_features(devX, feature_functions)\n",
    "\n",
    "    # just create vocabulary from features in *training* data.\n",
    "    feature_vocab=create_vocab(trainX_feat, top_n=100000)\n",
    "\n",
    "    trainX_ids=features_to_ids(trainX_feat, feature_vocab)\n",
    "    devX_ids=features_to_ids(devX_feat, feature_vocab)\n",
    "    \n",
    "    clf = linear_model.LogisticRegression(C=1, solver='lbfgs', penalty='l2', max_iter=10000)\n",
    "    clf.fit(trainX_ids, trainY)\n",
    "    \n",
    "    predictions=clf.predict(devX_ids)\n",
    "    \n",
    "    return clf, feature_vocab, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function majority_class(trainY, devY) calculates the majority class label based on the distribution of labels in the training set (trainY). It then assigns this majority class label to all instances in the development set (devY). This is a naive approach which serves as a baseline to compare different models using different features. If your model performance is worse than the majority votes, there are something wrong in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(trainY, devY):\n",
    "    labelCounts=Counter()\n",
    "    for label in trainY:\n",
    "        labelCounts[label]+=1\n",
    "    majority_class=labelCounts.most_common(1)[0][0]\n",
    "    \n",
    "    return [majority_class]*len(devY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(clf, vocab, n=10):\n",
    "\n",
    "    reverse_vocab=[None]*len(clf.coef_[0])\n",
    "    for k in vocab:\n",
    "        reverse_vocab[vocab[k]]=k\n",
    "        \n",
    "    for i, cat in enumerate(clf.classes_):\n",
    "        \n",
    "        weights=clf.coef_[i]\n",
    "\n",
    "        for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "            print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function unigram_feature(tokens) takes a list of tokens (tokens) as input and generates a feature dictionary (feats) representing the presence of each unigram (single word) in the tokenized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_feature(tokens):\n",
    "    feats={}\n",
    "    for word in tokens:\n",
    "        feats[\"UNIGRAM_%s\" % word]=1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preps={}\n",
    "with open(\"data/preposition_list.txt\") as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\"#\"):\n",
    "            preps[line.rstrip()]=1\n",
    "            \n",
    "def preposition_feature(tokens):\n",
    "    feats={}\n",
    "    for word in tokens:\n",
    "        if word in preps:\n",
    "            feats[\"PREP_%s\" % word]=1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function length_feature accepts a list of tokens as input and calculates two features related to the length of the tokens. First, it computes the total number of tokens in the utterance, which is stored in the \"utterance_length\" feature. Then, it calculates the average length of the words in the utterance by summing up the lengths of all the words and dividing the total by the number of tokens. This average word length is stored in the \"avg_word_length\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_feature(tokens):\n",
    "    feats={}\n",
    "    feats[\"utterance_length\"]=len(tokens)\n",
    "    \n",
    "    avg_word_length=0.\n",
    "    for word in tokens:\n",
    "        avg_word_length+=len(word)\n",
    "    avg_word_length/=len(tokens)\n",
    "    \n",
    "    feats[\"avg_word_length\"]=avg_word_length\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function readability_feature processes a list of tokens representing a piece of text by first joining them into a single string. Utilizing the textstat package, it then computes the Flesch Reading Ease score for the text, a metric indicating the ease of readability. This score is based on factors such as sentence length and syllable count per word, with higher scores signifying easier readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability_feature(tokens):\n",
    "    feats={}\n",
    "    data=' '.join(tokens)\n",
    "    feats[\"flesch_reading_ease\"]=textstat.flesch_reading_ease(data)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Function punctuation_feature takes a list of tokens (tokens) as input and creates a feature dictionary (feats) representing the presence of certain punctuation marks in the tokenized text. The function initializes a set punct containing common punctuation marks such as question marks, commas, periods, exclamation marks, semicolons, and colons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_feature(tokens):\n",
    "    punct=set([\"?\", \",\", \".\", \"!\", \";\", \":\"])\n",
    "    feats={}\n",
    "    for word in tokens:\n",
    "        if word in punct:\n",
    "            feats[\"PUNCT_%s\" % word]=1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(targets, features, filename, max_num):\n",
    "\n",
    "    random.seed(1) # for reproducibility\n",
    "\n",
    "    X, Y=read_data(filename, targets, max_num=max_num)\n",
    "    X=np.array(X, dtype=object)\n",
    "    Y=np.array(Y, dtype=object)\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "    \n",
    "    preds=[]\n",
    "    golds=[]\n",
    "    baseline=[]\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        clf, vocab, predictions=pipeline(X_train, X_test, y_train, y_test, features)\n",
    "        preds.extend(predictions)\n",
    "        golds.extend(y_test)\n",
    "        baseline.extend(majority_class(y_train, y_test))\n",
    "    \n",
    "    print(\"Majority class: %.3f (%s)\\n\" % (accuracy_score(baseline, golds), len(golds)))\n",
    "    print(\"Cross-validated accuracy: %.3f (%s)\\n\" % (accuracy_score(preds, golds), len(golds)))\n",
    "\n",
    "    # print weights from last fold\n",
    "    print_weights(clf, vocab, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's train a classifier to predict the character identity based on the *content* of their dialogue (effectively learning if different characters talk about kinds of different things).  How do the most characteristic features for each character accord with your own understanding of their language?\n",
    "\n",
    "The accuracies provide insights into the performance of the classifier with different sets of features. By comparing the accuracies achieved with each feature set, we can discern how effectively each set captures the underlying patterns in the data. Higher accuracies indicate that the corresponding feature set better discriminates between different classes, resulting in more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: 0.200 (1150)\n",
      "\n",
      "Cross-validated accuracy: 0.343 (1150)\n",
      "\n",
      "Frodo\t1.387\tUNIGRAM_smeagol\n",
      "Frodo\t1.162\tUNIGRAM_n't\n",
      "Frodo\t0.916\tUNIGRAM_mean\n",
      "Frodo\t0.914\tUNIGRAM_sleep\n",
      "Frodo\t0.904\tUNIGRAM_perhaps\n",
      "Frodo\t0.902\tUNIGRAM_last\n",
      "Frodo\t0.898\tUNIGRAM_boromir\n",
      "Frodo\t0.861\tUNIGRAM_am\n",
      "Frodo\t0.839\tUNIGRAM_hear\n",
      "Frodo\t0.832\tUNIGRAM_expect\n",
      "\n",
      "Gandalf\t1.115\tUNIGRAM_new\n",
      "Gandalf\t1.084\tUNIGRAM_course\n",
      "Gandalf\t0.911\tUNIGRAM_both\n",
      "Gandalf\t0.881\tUNIGRAM_night\n",
      "Gandalf\t0.876\tUNIGRAM_heard\n",
      "Gandalf\t0.849\tUNIGRAM_end\n",
      "Gandalf\t0.834\tUNIGRAM_wormtongue\n",
      "Gandalf\t0.810\tUNIGRAM_man\n",
      "Gandalf\t0.797\tUNIGRAM_understand\n",
      "Gandalf\t0.775\tUNIGRAM_know\n",
      "\n",
      "Gimli\t1.099\tUNIGRAM_twenty-one\n",
      "Gimli\t1.018\tUNIGRAM_kheled-zaram\n",
      "Gimli\t0.993\tUNIGRAM_indeed\n",
      "Gimli\t0.877\tUNIGRAM_had\n",
      "Gimli\t0.871\tUNIGRAM_middle-earth\n",
      "Gimli\t0.870\tUNIGRAM_durin\n",
      "Gimli\t0.863\tUNIGRAM_lost\n",
      "Gimli\t0.828\tUNIGRAM_paths\n",
      "Gimli\t0.794\tUNIGRAM_would\n",
      "Gimli\t0.794\tUNIGRAM_less\n",
      "\n",
      "Legolas\t1.744\tUNIGRAM_gimli\n",
      "Legolas\t1.329\tUNIGRAM_nimrodel\n",
      "Legolas\t1.125\tUNIGRAM_strange\n",
      "Legolas\t1.074\tUNIGRAM_elves\n",
      "Legolas\t0.948\tUNIGRAM_journeyed\n",
      "Legolas\t0.941\tUNIGRAM_nay\n",
      "Legolas\t0.912\tUNIGRAM_elf\n",
      "Legolas\t0.896\tUNIGRAM_lothlorien\n",
      "Legolas\t0.829\tUNIGRAM_many\n",
      "Legolas\t0.823\tUNIGRAM_alas\n",
      "\n",
      "Sam\t1.588\tUNIGRAM_sam\n",
      "Sam\t1.345\tUNIGRAM_n't\n",
      "Sam\t1.336\tUNIGRAM_'ll\n",
      "Sam\t1.333\tUNIGRAM_mr.\n",
      "Sam\t1.192\tUNIGRAM_'s\n",
      "Sam\t1.170\tUNIGRAM_'ve\n",
      "Sam\t1.066\tUNIGRAM_sorry\n",
      "Sam\t0.986\tUNIGRAM_oh\n",
      "Sam\t0.924\tUNIGRAM_never\n",
      "Sam\t0.864\tUNIGRAM_thought\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets={216: \"Frodo\", 106: \"Sam\", 49: \"Gandalf\", 317: \"Gimli\", 259: \"Legolas\"}\n",
    "process(targets, [unigram_feature], \"data/lotr.book.gz\", 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: 0.200 (2500)\n",
      "\n",
      "Cross-validated accuracy: 0.406 (2500)\n",
      "\n",
      "Dumbledore\t1.598\tUNIGRAM_voldemort\n",
      "Dumbledore\t1.450\tUNIGRAM_certainly\n",
      "Dumbledore\t1.419\tUNIGRAM_precisely\n",
      "Dumbledore\t1.280\tUNIGRAM_very\n",
      "Dumbledore\t1.106\tUNIGRAM_yes\n",
      "Dumbledore\t1.063\tUNIGRAM_indeed\n",
      "Dumbledore\t1.053\tUNIGRAM_alastor\n",
      "Dumbledore\t1.041\tUNIGRAM_correct\n",
      "Dumbledore\t0.988\tUNIGRAM_am\n",
      "Dumbledore\t0.915\tUNIGRAM_means\n",
      "\n",
      "Hagrid\t2.686\tUNIGRAM_'\n",
      "Hagrid\t2.322\tUNIGRAM_yeh\n",
      "Hagrid\t2.220\tUNIGRAM_yer\n",
      "Hagrid\t1.686\tUNIGRAM_tha\n",
      "Hagrid\t1.549\tUNIGRAM_eh\n",
      "Hagrid\t1.416\tUNIGRAM_ter\n",
      "Hagrid\t1.358\tUNIGRAM_'em\n",
      "Hagrid\t1.316\tUNIGRAM_rubbish\n",
      "Hagrid\t1.145\tUNIGRAM_us\n",
      "Hagrid\t1.010\tUNIGRAM_ca\n",
      "\n",
      "Harry\t1.207\tUNIGRAM_er\n",
      "Harry\t1.206\tUNIGRAM_matter\n",
      "Harry\t1.043\tUNIGRAM_move\n",
      "Harry\t0.961\tUNIGRAM_thanks\n",
      "Harry\t0.942\tUNIGRAM_hagger\n",
      "Harry\t0.941\tUNIGRAM_mind\n",
      "Harry\t0.920\tUNIGRAM_w-what\n",
      "Harry\t0.896\tUNIGRAM_dobby\n",
      "Harry\t0.892\tUNIGRAM_surprised\n",
      "Harry\t0.864\tUNIGRAM_yeah\n",
      "\n",
      "Hermione\t1.025\tUNIGRAM_learn\n",
      "Hermione\t0.988\tUNIGRAM_`\n",
      "Hermione\t0.933\tUNIGRAM_hidden\n",
      "Hermione\t0.930\tUNIGRAM_granger\n",
      "Hermione\t0.905\tUNIGRAM_charm\n",
      "Hermione\t0.894\tUNIGRAM_neville\n",
      "Hermione\t0.889\tUNIGRAM_cho\n",
      "Hermione\t0.883\tUNIGRAM_just\n",
      "Hermione\t0.873\tUNIGRAM_anything\n",
      "Hermione\t0.872\tUNIGRAM_loved\n",
      "\n",
      "Ron\t1.347\tUNIGRAM_mate\n",
      "Ron\t1.337\tUNIGRAM_stupid\n",
      "Ron\t1.306\tUNIGRAM_hermione\n",
      "Ron\t1.269\tUNIGRAM_yeah\n",
      "Ron\t1.082\tUNIGRAM_eat\n",
      "Ron\t1.044\tUNIGRAM_anyone\n",
      "Ron\t1.034\tUNIGRAM_cool\n",
      "Ron\t1.026\tUNIGRAM_talk\n",
      "Ron\t1.023\tUNIGRAM_face\n",
      "Ron\t1.018\tUNIGRAM_those\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets={343: \"Harry\", 247: \"Ron\", 302: \"Hermione\", 352: \"Dumbledore\", 298: \"Hagrid\"}\n",
    "process(targets, [unigram_feature], \"data/harry_potter.book.gz\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's train a classifier on primarily *stylistic* features (average word length, average utterance length, frequency of specific punctuation, reading difficulty).  Can we still see measurable differences between characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: 0.200 (1150)\n",
      "\n",
      "Cross-validated accuracy: 0.260 (1150)\n",
      "\n",
      "Frodo\t0.353\tPUNCT_?\n",
      "Frodo\t0.201\tPUNCT_;\n",
      "Frodo\t0.190\tPUNCT_.\n",
      "Frodo\t0.002\tutterance_length\n",
      "Frodo\t-0.008\tflesch_reading_ease\n",
      "Frodo\t-0.092\tPUNCT_!\n",
      "Frodo\t-0.121\tPUNCT_:\n",
      "Frodo\t-0.166\tPUNCT_,\n",
      "Frodo\t-0.483\tavg_word_length\n",
      "\n",
      "Gandalf\t0.016\tPUNCT_,\n",
      "Gandalf\t0.006\tutterance_length\n",
      "Gandalf\t-0.001\tflesch_reading_ease\n",
      "Gandalf\t-0.030\tPUNCT_!\n",
      "Gandalf\t-0.035\tavg_word_length\n",
      "Gandalf\t-0.041\tPUNCT_;\n",
      "Gandalf\t-0.076\tPUNCT_.\n",
      "Gandalf\t-0.237\tPUNCT_?\n",
      "Gandalf\t-0.267\tPUNCT_:\n",
      "\n",
      "Gimli\t0.498\tavg_word_length\n",
      "Gimli\t0.313\tPUNCT_:\n",
      "Gimli\t0.001\tflesch_reading_ease\n",
      "Gimli\t-0.007\tutterance_length\n",
      "Gimli\t-0.016\tPUNCT_,\n",
      "Gimli\t-0.152\tPUNCT_.\n",
      "Gimli\t-0.256\tPUNCT_?\n",
      "Gimli\t-0.296\tPUNCT_!\n",
      "Gimli\t-0.859\tPUNCT_;\n",
      "\n",
      "Legolas\t0.715\tPUNCT_:\n",
      "Legolas\t0.374\tavg_word_length\n",
      "Legolas\t0.116\tPUNCT_;\n",
      "Legolas\t0.112\tPUNCT_!\n",
      "Legolas\t0.012\tflesch_reading_ease\n",
      "Legolas\t-0.002\tutterance_length\n",
      "Legolas\t-0.050\tPUNCT_,\n",
      "Legolas\t-0.365\tPUNCT_.\n",
      "Legolas\t-0.422\tPUNCT_?\n",
      "\n",
      "Sam\t0.582\tPUNCT_;\n",
      "Sam\t0.562\tPUNCT_?\n",
      "Sam\t0.403\tPUNCT_.\n",
      "Sam\t0.307\tPUNCT_!\n",
      "Sam\t0.216\tPUNCT_,\n",
      "Sam\t0.001\tutterance_length\n",
      "Sam\t-0.004\tflesch_reading_ease\n",
      "Sam\t-0.353\tavg_word_length\n",
      "Sam\t-0.640\tPUNCT_:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets={216: \"Frodo\", 106: \"Sam\", 49: \"Gandalf\", 317: \"Gimli\", 259: \"Legolas\"}\n",
    "process(targets, [length_feature, readability_feature, punctuation_feature], \"data/lotr.book.gz\", 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: 0.200 (2500)\n",
      "\n",
      "Cross-validated accuracy: 0.263 (2500)\n",
      "\n",
      "Dumbledore\t0.291\tPUNCT_,\n",
      "Dumbledore\t0.158\tavg_word_length\n",
      "Dumbledore\t0.102\tPUNCT_.\n",
      "Dumbledore\t0.003\tutterance_length\n",
      "Dumbledore\t-0.006\tflesch_reading_ease\n",
      "Dumbledore\t-0.050\tPUNCT_:\n",
      "Dumbledore\t-0.145\tPUNCT_;\n",
      "Dumbledore\t-0.488\tPUNCT_?\n",
      "Dumbledore\t-1.038\tPUNCT_!\n",
      "\n",
      "Hagrid\t0.177\tPUNCT_!\n",
      "Hagrid\t0.080\tPUNCT_,\n",
      "Hagrid\t0.018\tPUNCT_.\n",
      "Hagrid\t0.012\tutterance_length\n",
      "Hagrid\t-0.004\tflesch_reading_ease\n",
      "Hagrid\t-0.050\tPUNCT_?\n",
      "Hagrid\t-0.175\tPUNCT_;\n",
      "Hagrid\t-0.259\tPUNCT_:\n",
      "Hagrid\t-0.559\tavg_word_length\n",
      "\n",
      "Harry\t0.537\tPUNCT_:\n",
      "Harry\t0.215\tPUNCT_.\n",
      "Harry\t0.152\tPUNCT_!\n",
      "Harry\t0.120\tPUNCT_?\n",
      "Harry\t0.082\tPUNCT_;\n",
      "Harry\t0.000\tflesch_reading_ease\n",
      "Harry\t-0.000\tutterance_length\n",
      "Harry\t-0.051\tavg_word_length\n",
      "Harry\t-0.362\tPUNCT_,\n",
      "\n",
      "Hermione\t0.586\tPUNCT_!\n",
      "Hermione\t0.318\tPUNCT_?\n",
      "Hermione\t0.271\tPUNCT_;\n",
      "Hermione\t0.118\tPUNCT_,\n",
      "Hermione\t0.113\tavg_word_length\n",
      "Hermione\t0.000\tflesch_reading_ease\n",
      "Hermione\t-0.008\tutterance_length\n",
      "Hermione\t-0.063\tPUNCT_.\n",
      "Hermione\t-0.122\tPUNCT_:\n",
      "\n",
      "Ron\t0.338\tavg_word_length\n",
      "Ron\t0.123\tPUNCT_!\n",
      "Ron\t0.100\tPUNCT_?\n",
      "Ron\t0.009\tflesch_reading_ease\n",
      "Ron\t-0.007\tutterance_length\n",
      "Ron\t-0.033\tPUNCT_;\n",
      "Ron\t-0.106\tPUNCT_:\n",
      "Ron\t-0.128\tPUNCT_,\n",
      "Ron\t-0.272\tPUNCT_.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets={343: \"Harry\", 247: \"Ron\", 302: \"Hermione\", 352: \"Dumbledore\", 298: \"Hagrid\"}\n",
    "process(targets, [length_feature, readability_feature, punctuation_feature], \"data/harry_potter.book.gz\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these results, let's brainstorm two ideas:\n",
    "\n",
    "* How could we use these distinctive voices to build a better system for speaker attribution?\n",
    "* How could we use these results to build a model for *free indirect discourse*? (i.e., where a character's voice influences the narration.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
